{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Jayant Chaudhari_chaudharijay2000@gmail.com_Assignment No. 25_CNN on CIFAR dataset_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tN4ol9IZiFRQ"
      },
      "source": [
        "# CNN on CIFAR dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mdQCFdamHal",
        "colab_type": "text"
      },
      "source": [
        "### CIFAR-10 by DenseNet Implementation\n",
        "Cifar-10 is a popular dataset available at https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "We plan to solve this problem by the use of Densenet Architecture. An awesome way of solving this problem with help of Resnet is available at keras website https://keras.io/examples/cifar10_resnet/Â¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MchLA5yEmHan",
        "colab_type": "text"
      },
      "source": [
        "### But why not Transfer Learning?\n",
        "As The weights trained on ResNet or DenseNet are for ImageNet which compromises of Images of Dimension 224x224 and the image dimensions in CIFAR-10 are of 32x32 that means we cannot upsample that much anyhow. So instead we will use the same architecture of DenseNet explained in https://arxiv.org/pdf/1608.06993.pdf and will try to get as much as Accuracy possible on the dataset.\n",
        "PS. We are using Google Colab for the training purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IMDhvIgsiFec",
        "outputId": "59251e13-536a-4e3e-adb4-9dad04b82294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D, Dropout, BatchNormalization, Activation, Concatenate\n",
        "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Input, AveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.optimizers import SGD, Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras import backend as k"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8JSHIN1iGid",
        "colab": {}
      },
      "source": [
        "# Allocate the memory as needed instead of preloading\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "as2_uIZ5iwIF",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pTlmuD9Qiycd",
        "colab": {}
      },
      "source": [
        "# Loading the CIFAR data from the keras dataset\n",
        "num_classes = 10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Chyu2zOqi0ZW",
        "colab": {}
      },
      "source": [
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hLFwysYzi3Ql",
        "colab": {}
      },
      "source": [
        "# convert to one hot encoing \n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XhlTM69Ji5ge",
        "outputId": "11c23e71-a833-4f3d-dc45-9b6784a65ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mR5zs9Rmi7o_",
        "outputId": "777b271a-ab0f-44f4-e8cf-4f0d6abc1f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ER7J2Zmi9UB",
        "colab": {}
      },
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CEF-ukL-jEjb",
        "outputId": "3313315b-a63f-4ef8-d693-967bbfd92f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(x_train[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5e5e1497f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWmKmUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-283YLfWjH1s",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "compression = 0.5\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-KQp7QgejLrA",
        "colab": {}
      },
      "source": [
        "## transition Block\n",
        "compression = 0.5\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VOY0ldA-jOb3",
        "colab": {}
      },
      "source": [
        "from keras import layers \n",
        "\n",
        "#output layer\n",
        "compression = 0.5\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input) \n",
        "    relu = Activation('relu')(BatchNorm) \n",
        "    cv = Conv2D(10, (1,1), use_bias=False ,padding='same')(relu) \n",
        "    avg = AveragePooling2D(pool_size=(2,2))(cv) \n",
        "    pooling = GlobalAveragePooling2D()(avg)\n",
        "    output = Activation('softmax')(pooling)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYTzzN_ex5Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 35\n",
        "l = 6\n",
        "num_filter = 64\n",
        "compression = 0.5\n",
        "dropout_rate = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6021aFdyF2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "84b56daa-0b90-4e2d-b8fc-2818f9de2f4c"
      },
      "source": [
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IDiEkimyGDH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2bc9a8a1-060e-4443-8870-a6db343e2725"
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   1728        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 96)   0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 96)   384         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 96)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   27648       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   36864       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 160)  0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   46080       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 192)  0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 192)  768         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 32)   55296       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 224)  0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 224)  896         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 224)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 32)   64512       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 256)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 32)   8192        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 32)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   9216        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 16, 16, 64)   0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   18432       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 16, 16, 96)   0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   384         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   27648       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 16, 16, 128)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   36864       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 16, 16, 160)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 160)  640         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 160)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   46080       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 16, 16, 192)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 192)  768         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 192)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 32)   55296       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 224)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 224)  896         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 224)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 32)   7168        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 8, 8, 32)     0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 32)     128         average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 32)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 32)     9216        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 8, 8, 64)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 32)     18432       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 8, 8, 96)     0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 96)     384         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 96)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 32)     27648       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 8, 8, 128)    0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 128)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 32)     36864       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 8, 8, 160)    0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 160)    640         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 160)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 32)     46080       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 8, 8, 192)    0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 192)    768         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 192)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 32)     55296       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 8, 8, 224)    0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 224)    896         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 224)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 32)     7168        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 32)     0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 4, 4, 32)     128         average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 4, 4, 32)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 32)     9216        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 4, 4, 64)     0           average_pooling2d_3[0][0]        \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 4, 4, 64)     256         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 64)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 4, 4, 32)     18432       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 4, 4, 96)     0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 4, 4, 96)     384         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 96)     0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 32)     27648       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 4, 4, 128)    0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 4, 4, 128)    512         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 4, 4, 128)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 32)     36864       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 4, 4, 160)    0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 160)    640         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 160)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 32)     46080       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 4, 4, 192)    0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 4, 4, 192)    768         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 4, 4, 192)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 32)     55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 4, 4, 224)    0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 4, 4, 224)    896         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 4, 4, 224)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 10)     2240        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 2, 2, 10)     0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 10)           0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 10)           0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 871,168\n",
            "Trainable params: 863,552\n",
            "Non-trainable params: 7,616\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_N-b2FkyGOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcazid_cyGZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = x_train.mean(0)\n",
        "std = x_train.std(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQIe8s9fyGjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(dataset):\n",
        "    dataset -= mean\n",
        "    dataset /= std\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Voox9uyGtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = preprocess_data(x_train)\n",
        "x_test = preprocess_data(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdK5gDsgyG4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augementation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen_train = ImageDataGenerator(\n",
        "    width_shift_range=0.125,\n",
        "    height_shift_range=0.125,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "datagen_train.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQzOOdZQzj8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
        "\n",
        "checkpoint_3 = ModelCheckpoint(\"model_dense.h5\",monitor=\"val_acc\",mode=\"max\",save_best_only = True,verbose=1) \n",
        "NAME = 'model_dense' \n",
        "tensorboard2 = TensorBoard(log_dir='logss\\{}'.format(NAME),update_freq='epoch',batch_size=batch_size) \n",
        "callbacks2 = [tensorboard2,checkpoint_3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYQ_LpO4zkGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-hDLibAzyvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad6af9c0-80f2-41c0-a226-f1396a1b9d95"
      },
      "source": [
        "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=(len(x_train)/batch_size)*5,\n",
        "    epochs=epochs,\n",
        "    verbose = 1,\n",
        "    validation_data=(x_test, y_test),\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "1954/1953 [==============================] - 348s 178ms/step - loss: 0.8636 - acc: 0.6934 - val_loss: 0.7326 - val_acc: 0.7601\n",
            "Epoch 2/35\n",
            "1954/1953 [==============================] - 330s 169ms/step - loss: 0.4543 - acc: 0.8426 - val_loss: 0.5687 - val_acc: 0.8151\n",
            "Epoch 3/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.3417 - acc: 0.8810 - val_loss: 0.6181 - val_acc: 0.8186\n",
            "Epoch 4/35\n",
            "1954/1953 [==============================] - 332s 170ms/step - loss: 0.2757 - acc: 0.9040 - val_loss: 0.4066 - val_acc: 0.8688\n",
            "Epoch 5/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.2287 - acc: 0.9198 - val_loss: 0.4511 - val_acc: 0.8612\n",
            "Epoch 6/35\n",
            "1954/1953 [==============================] - 331s 170ms/step - loss: 0.1922 - acc: 0.9328 - val_loss: 0.4016 - val_acc: 0.8775\n",
            "Epoch 7/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.1650 - acc: 0.9419 - val_loss: 0.5034 - val_acc: 0.8633\n",
            "Epoch 8/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.1428 - acc: 0.9495 - val_loss: 0.5385 - val_acc: 0.8616\n",
            "Epoch 9/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.1231 - acc: 0.9560 - val_loss: 0.4800 - val_acc: 0.8756\n",
            "Epoch 10/35\n",
            "1954/1953 [==============================] - 330s 169ms/step - loss: 0.1099 - acc: 0.9605 - val_loss: 0.4703 - val_acc: 0.8782\n",
            "Epoch 11/35\n",
            "1954/1953 [==============================] - 330s 169ms/step - loss: 0.0964 - acc: 0.9655 - val_loss: 0.4458 - val_acc: 0.8803\n",
            "Epoch 12/35\n",
            "1954/1953 [==============================] - 330s 169ms/step - loss: 0.0879 - acc: 0.9683 - val_loss: 0.4594 - val_acc: 0.8882\n",
            "Epoch 13/35\n",
            "1954/1953 [==============================] - 330s 169ms/step - loss: 0.0792 - acc: 0.9717 - val_loss: 0.4088 - val_acc: 0.8968\n",
            "Epoch 14/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0712 - acc: 0.9743 - val_loss: 0.5100 - val_acc: 0.8776\n",
            "Epoch 15/35\n",
            "1954/1953 [==============================] - 331s 170ms/step - loss: 0.0664 - acc: 0.9763 - val_loss: 0.5088 - val_acc: 0.8854\n",
            "Epoch 16/35\n",
            "1954/1953 [==============================] - 330s 169ms/step - loss: 0.0619 - acc: 0.9781 - val_loss: 0.4823 - val_acc: 0.8903\n",
            "Epoch 17/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0566 - acc: 0.9796 - val_loss: 0.4534 - val_acc: 0.8979\n",
            "Epoch 18/35\n",
            "1954/1953 [==============================] - 330s 169ms/step - loss: 0.0532 - acc: 0.9813 - val_loss: 0.5110 - val_acc: 0.8904\n",
            "Epoch 19/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0501 - acc: 0.9822 - val_loss: 0.4118 - val_acc: 0.9032\n",
            "Epoch 20/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0474 - acc: 0.9832 - val_loss: 0.4715 - val_acc: 0.8966\n",
            "Epoch 21/35\n",
            "1954/1953 [==============================] - 330s 169ms/step - loss: 0.0452 - acc: 0.9840 - val_loss: 0.5049 - val_acc: 0.8910\n",
            "Epoch 22/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0432 - acc: 0.9847 - val_loss: 0.5037 - val_acc: 0.8963\n",
            "Epoch 23/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0390 - acc: 0.9864 - val_loss: 0.5166 - val_acc: 0.8996\n",
            "Epoch 24/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0381 - acc: 0.9867 - val_loss: 0.4750 - val_acc: 0.9045\n",
            "Epoch 25/35\n",
            "1954/1953 [==============================] - 332s 170ms/step - loss: 0.0369 - acc: 0.9870 - val_loss: 0.4700 - val_acc: 0.9066\n",
            "Epoch 26/35\n",
            "1954/1953 [==============================] - 332s 170ms/step - loss: 0.0338 - acc: 0.9880 - val_loss: 0.5411 - val_acc: 0.8958\n",
            "Epoch 27/35\n",
            "1954/1953 [==============================] - 332s 170ms/step - loss: 0.0335 - acc: 0.9881 - val_loss: 0.4692 - val_acc: 0.9073\n",
            "Epoch 28/35\n",
            "1954/1953 [==============================] - 332s 170ms/step - loss: 0.0320 - acc: 0.9886 - val_loss: 0.4441 - val_acc: 0.9066\n",
            "Epoch 29/35\n",
            "1954/1953 [==============================] - 332s 170ms/step - loss: 0.0309 - acc: 0.9893 - val_loss: 0.5578 - val_acc: 0.8950\n",
            "Epoch 30/35\n",
            "1954/1953 [==============================] - 332s 170ms/step - loss: 0.0307 - acc: 0.9892 - val_loss: 0.5403 - val_acc: 0.8983\n",
            "Epoch 31/35\n",
            "1954/1953 [==============================] - 331s 170ms/step - loss: 0.0282 - acc: 0.9903 - val_loss: 0.4933 - val_acc: 0.9034\n",
            "Epoch 32/35\n",
            "1954/1953 [==============================] - 331s 170ms/step - loss: 0.0276 - acc: 0.9902 - val_loss: 0.4794 - val_acc: 0.9102\n",
            "Epoch 33/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0278 - acc: 0.9904 - val_loss: 0.6699 - val_acc: 0.8815\n",
            "Epoch 34/35\n",
            "1954/1953 [==============================] - 331s 169ms/step - loss: 0.0255 - acc: 0.9910 - val_loss: 0.4926 - val_acc: 0.9079\n",
            "Epoch 35/35\n",
            "1954/1953 [==============================] - 331s 170ms/step - loss: 0.0253 - acc: 0.9912 - val_loss: 0.5071 - val_acc: 0.9066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aYtH8nu5gL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "e2b48c1b-1f5c-4e64-dd13-d56beb75704b"
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 465us/step\n",
            "Test loss: 0.5070862675895914\n",
            "Test accuracy: 0.9066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6rZFrDUFK-TV",
        "outputId": "ad7b6bd4-885c-472d-8c48-7ae3a28e0051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "img_to_visualize = x_train[0]\n",
        "plt.imshow(img_to_visualize)\n",
        "\n",
        "img_to_visualize = np.expand_dims(img_to_visualize, axis=0)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIolQsoskQskukoj/Aw20d5n5h5q0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UuqQ3KP9jXaQ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}